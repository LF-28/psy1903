file.create("reports/npt_group.qmd")
file.create("reports/npt_group.qmd")
file.create("reports/npt_group.qmd")
getwd()
stwd("/Users/efried/Desktop/psy1903/web/npt_project")
setwdstwd("/Users/efried/Desktop/psy1903/web/npt_project")
setwd("/Users/efried/Desktop/psy1903/web/npt_project")
R version 4.5.1 (2025-06-13) -- "Great Square Root"
file.create("reports/npt_group.qmd")
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
library()
library(here)
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
process_participant <- function(file_name) {
## Derive a subject id from the filename (no extension)
subject_id <- sub("\\.csv$", "", basename(file_name))
## Read the raw CSV
# participant_data <- read.csv(file_path, stringsAsFactors = FALSE)
participant_data <- read.csv(
here::here("data", "raw", file_name),
stringsAsFactors = FALSE
)
#### Questionnaire score ------------------------------------------------
## Score questionnaire with our defaults (reverse 2,4,7 on 0–4 scale)
tef10_score <- score_questionnaire(
json_string = participant_data[participant_data$trialType == "questionnaire", "response"],
reverse = c(2, 4, 7),
scale_min = 0L,
scale_max = 4L
)
#### Behavioral summary -------------------------------------------------
## Filter and summarize behavioral data (250–900 ms)
behavior <- summarize_behavior(participant_data, rt_min = 250, rt_max = 900)
#### Save participant summary -------------------------------------------
dir.create("../data/cleaned/participants", recursive = TRUE, showWarnings = FALSE)
## Combine into a single-row participant summary
df_clean <- data.frame(
subject_id = subject_id,
tef10_score = tef10_score,
behavior = behavior
)
## Save summary CSV to cleaned/participants
## Save summary CSV to cleaned/participants
dir.create(
here::here("data", "cleaned", "participants"),
recursive = TRUE,
showWarnings = FALSE
)
# write.csv(
#     df_clean,
#     here::here("data", "cleaned", paste0(subject_id, "_processed.csv")),
#     row.names = FALSE
# )
# write.csv(
#     df_clean,
#     file = file.path("/Users/efried/Desktop/psy1903/web/npt_project/data/cleaned/participants", paste0(subject_id, ".csv")),
#     row.names = FALSE
#) ##I had to add the full path here for a csv to save
#### Return output ------------------------------------------------------
stopifnot(nrow(df_clean) == 1)  # one row per participant
return(df_clean)
}
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
source("scripts/process_participant.R")
processed <- process_participant("npt-experiment-2025-11-05-10-08-45.csv")
source("scripts/process_participant.R")
processed <- process_participant("npt-experiment-2025-11-05-10-33-05.csv")
if (!require(here)) install.packages("here")
library(here)
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
processed <- process_participant("npt-experiment-2025-11-05-10-33-05.csv")
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
source("scripts/process_participant.R")
processed <- process_participant("npt-experiment-2025-11-05-10-33-05.csv")
getwd()
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here::here("data/cleaned/study_level.csv"))
library(here)
getwd()
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here::here("data/cleaned/study_level.csv"))
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here::here("npt_project/data/cleaned/study_level.csv"))
getwd()
study_level <- read.csv(here::here("data/cleaned/study_level.csv"))
getwd()
getwd()
here::here()
list.files(here::here("data", "cleaned"))
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here::here("data/cleaned/study_level.csv"))
library(here)
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here::here("data/cleaned/study_level.csv"))
# Quick inspection
head(study_level)
str(study_level)
summary(study_level)
## Replace Column Names
names(study_level) <- c("subject_id", "tef10_score", "practice_mean_rt", "practice_acc", "magnitude_mean_rt", "magnitude_acc", "parity_mean_rt", "parity_acc", "practice_sd_rt", "magnitude_sd_rt", "parity_sd_rt")
write.csv(study_level, here::here("data/cleaned/study_level.csv"), row.names = FALSE)
# A) Reaction time difference (complete this line together)
# hint: subtract magnitude mean RT from parity mean RT
study_level$rt_diff <- study_level$parity_mean_rt - study_level$magnitude_mean_rt
# B) Accuracy difference (complete together)
study_level$acc_diff <- study_level$parity_mean_acc - study_level$magnitude_mean_acc
View(study_level)
# A) Reaction time difference (complete this line together)
# hint: subtract magnitude mean RT from parity mean RT
study_level$rt_diff <- study_level$parity_mean_rt - study_level$magnitude_mean_rt
# B) Accuracy difference (complete together)
study_level$acc_diff <- study_level$parity_acc - study_level$magnitude_acc
# C) Overall averages across conditions
study_level$mean_rt_overall  <- rowMeans(
study_level[, c("magnitude_mean_rt", "parity_mean_rt")],
na.rm = TRUE
)
study_level$mean_acc_overall <- rowMeans(
study_level[, c("magnitude_acc", "parity_acc")],
na.rm = TRUE
)
# Peek at the new columns
head(study_level[, c("subject_id", "rt_diff", "acc_diff",
"mean_rt_overall", "mean_acc_overall")])
# Class-level means
colMeans(study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff")],
na.rm = TRUE)
# Class-level variability (standard deviations)
sapply(study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff")],
sd, na.rm = TRUE)
# Create a focus grouping variable from tef10_score
focus_cut <- mean(study_level$tef10_score, na.rm = TRUE)
study_level$focus_group <- ifelse(study_level$tef10_score >= focus_cut,
"High Focus", "Low Focus")
# Check group counts
table(study_level$focus_group)
# Aggregate reaction times and differences by focus group
rt_by_focus <- aggregate(
study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff")],
by = list(Focus = study_level$focus_group),
FUN = mean
)
rt_by_focus
# Aggregate accuracies and differences by focus group
acc_by_focus <- aggregate(
study_level[, c("magnitude_acc",
"parity_acc",
"acc_diff")],
by = list(Focus = study_level$focus_group),
FUN = mean
)
acc_by_focus
str(study_level)
# What do we notice here?
# Summaries for key variables
summary(study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff",
"magnitude_acc",
"parity_acc",
"acc_diff")])
# Optional exploration: association between overall RT and overall accuracy
cor(study_level$mean_rt_overall, study_level$mean_acc_overall, use = "complete.obs")
# Make an output directory for tables if needed
dir.create(here("output/tables"), recursive = TRUE, showWarnings = FALSE)
# Build a compact one-row table of overall means and SDs
group_summary <- data.frame(
mean_magnitude_rt = mean(study_level$magnitude_mean_rt, na.rm = TRUE),
mean_parity_rt    = mean(study_level$parity_mean_rt,    na.rm = TRUE),
mean_rt_diff      = mean(study_level$rt_diff,                    na.rm = TRUE),
sd_magnitude_rt   = sd(study_level$magnitude_mean_rt,   na.rm = TRUE),
sd_parity_rt      = sd(study_level$parity_mean_rt,      na.rm = TRUE),
sd_rt_diff        = sd(study_level$rt_diff,                      na.rm = TRUE)
)
# Preview and save
group_summary
write.csv(group_summary, here("output/tables/group_summary.csv"), row.names = FALSE)
saveRDS(group_summary, here("output/tables/group_summary.rds"))
# Confirm
file.exists(here("output/tables/group_summary.csv"))
# Check for missing values
anyNA(study_level)
# Check number of participants
nrow(study_level)
source("../scripts/score_questionnaire.R")
source("../scripts/summarize_behavior.R")
source("../scripts/process_participant.R")
setwd("../")
getwd()
# Create full project folder structure under psy1903/web/
setwd("~/Desktop/psy1903") # Update to your path
dir.create("web/w11_taskset/data/raw", recursive = TRUE, showWarnings = FALSE)
dir.create("web/w11_taskset/data/cleaned", recursive = TRUE, showWarnings = FALSE)
dir.create("web/w11_taskset/scripts", recursive = TRUE, showWarnings = FALSE)
dir.create("web/w11_taskset/reports", recursive = TRUE, showWarnings = FALSE)
# Create placeholder R Script and Quarto Report files
file.create("web/w11_taskset/scripts/score_questionnaire.R")
file.create("web/w11_taskset/scripts/compute_rt_if_missing.R")
file.create("web/w11_taskset/scripts/process_participant.R")
file.create("web/w11_taskset/scripts/summarize_behavior.R”)
file.create("web/w11_taskset/reports/w11_taskset.qmd")
file.create("web/w11_taskset/scripts/summarize_behavior.R")
file.create("web/w11_taskset/reports/w11_taskset.qmd")
file.create("web/w11_taskset/w11_taskset.RProj")
project_text <- "Version: 1.0\n\nRestoreWorkspace: Default\nSaveWorkspace: Default\nAlwaysSaveHistory: Default\n\nEnableCodeIndexing: Yes\nUseSpacesForTab: Yes\nNumSpacesForTab: 4\nEncoding: UTF-8\n\nRnwWeave: Sweave\nLaTeX: pdfLaTeX"
writeLines(project_text, "web/npt_project/npt_project.RProj")
