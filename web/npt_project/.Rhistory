file.create("reports/npt_group.qmd")
file.create("reports/npt_group.qmd")
file.create("reports/npt_group.qmd")
getwd()
stwd("/Users/efried/Desktop/psy1903/web/npt_project")
setwdstwd("/Users/efried/Desktop/psy1903/web/npt_project")
setwd("/Users/efried/Desktop/psy1903/web/npt_project")
R version 4.5.1 (2025-06-13) -- "Great Square Root"
file.create("reports/npt_group.qmd")
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
library()
library(here)
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
process_participant <- function(file_name) {
## Derive a subject id from the filename (no extension)
subject_id <- sub("\\.csv$", "", basename(file_name))
## Read the raw CSV
# participant_data <- read.csv(file_path, stringsAsFactors = FALSE)
participant_data <- read.csv(
here::here("data", "raw", file_name),
stringsAsFactors = FALSE
)
#### Questionnaire score ------------------------------------------------
## Score questionnaire with our defaults (reverse 2,4,7 on 0–4 scale)
tef10_score <- score_questionnaire(
json_string = participant_data[participant_data$trialType == "questionnaire", "response"],
reverse = c(2, 4, 7),
scale_min = 0L,
scale_max = 4L
)
#### Behavioral summary -------------------------------------------------
## Filter and summarize behavioral data (250–900 ms)
behavior <- summarize_behavior(participant_data, rt_min = 250, rt_max = 900)
#### Save participant summary -------------------------------------------
dir.create("../data/cleaned/participants", recursive = TRUE, showWarnings = FALSE)
## Combine into a single-row participant summary
df_clean <- data.frame(
subject_id = subject_id,
tef10_score = tef10_score,
behavior = behavior
)
## Save summary CSV to cleaned/participants
## Save summary CSV to cleaned/participants
dir.create(
here::here("data", "cleaned", "participants"),
recursive = TRUE,
showWarnings = FALSE
)
# write.csv(
#     df_clean,
#     here::here("data", "cleaned", paste0(subject_id, "_processed.csv")),
#     row.names = FALSE
# )
# write.csv(
#     df_clean,
#     file = file.path("/Users/efried/Desktop/psy1903/web/npt_project/data/cleaned/participants", paste0(subject_id, ".csv")),
#     row.names = FALSE
#) ##I had to add the full path here for a csv to save
#### Return output ------------------------------------------------------
stopifnot(nrow(df_clean) == 1)  # one row per participant
return(df_clean)
}
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
source("scripts/process_participant.R")
processed <- process_participant("npt-experiment-2025-11-05-10-08-45.csv")
source("scripts/process_participant.R")
processed <- process_participant("npt-experiment-2025-11-05-10-33-05.csv")
if (!require(here)) install.packages("here")
library(here)
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
processed <- process_participant("npt-experiment-2025-11-05-10-33-05.csv")
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
source("scripts/process_participant.R")
processed <- process_participant("npt-experiment-2025-11-05-10-33-05.csv")
getwd()
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here::here("data/cleaned/study_level.csv"))
library(here)
getwd()
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here::here("data/cleaned/study_level.csv"))
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here::here("npt_project/data/cleaned/study_level.csv"))
getwd()
study_level <- read.csv(here::here("data/cleaned/study_level.csv"))
getwd()
getwd()
here::here()
list.files(here::here("data", "cleaned"))
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here::here("data/cleaned/study_level.csv"))
library(here)
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here::here("data/cleaned/study_level.csv"))
# Quick inspection
head(study_level)
str(study_level)
summary(study_level)
## Replace Column Names
names(study_level) <- c("subject_id", "tef10_score", "practice_mean_rt", "practice_acc", "magnitude_mean_rt", "magnitude_acc", "parity_mean_rt", "parity_acc", "practice_sd_rt", "magnitude_sd_rt", "parity_sd_rt")
write.csv(study_level, here::here("data/cleaned/study_level.csv"), row.names = FALSE)
# A) Reaction time difference (complete this line together)
# hint: subtract magnitude mean RT from parity mean RT
study_level$rt_diff <- study_level$parity_mean_rt - study_level$magnitude_mean_rt
# B) Accuracy difference (complete together)
study_level$acc_diff <- study_level$parity_mean_acc - study_level$magnitude_mean_acc
View(study_level)
# A) Reaction time difference (complete this line together)
# hint: subtract magnitude mean RT from parity mean RT
study_level$rt_diff <- study_level$parity_mean_rt - study_level$magnitude_mean_rt
# B) Accuracy difference (complete together)
study_level$acc_diff <- study_level$parity_acc - study_level$magnitude_acc
# C) Overall averages across conditions
study_level$mean_rt_overall  <- rowMeans(
study_level[, c("magnitude_mean_rt", "parity_mean_rt")],
na.rm = TRUE
)
study_level$mean_acc_overall <- rowMeans(
study_level[, c("magnitude_acc", "parity_acc")],
na.rm = TRUE
)
# Peek at the new columns
head(study_level[, c("subject_id", "rt_diff", "acc_diff",
"mean_rt_overall", "mean_acc_overall")])
# Class-level means
colMeans(study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff")],
na.rm = TRUE)
# Class-level variability (standard deviations)
sapply(study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff")],
sd, na.rm = TRUE)
# Create a focus grouping variable from tef10_score
focus_cut <- mean(study_level$tef10_score, na.rm = TRUE)
study_level$focus_group <- ifelse(study_level$tef10_score >= focus_cut,
"High Focus", "Low Focus")
# Check group counts
table(study_level$focus_group)
# Aggregate reaction times and differences by focus group
rt_by_focus <- aggregate(
study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff")],
by = list(Focus = study_level$focus_group),
FUN = mean
)
rt_by_focus
# Aggregate accuracies and differences by focus group
acc_by_focus <- aggregate(
study_level[, c("magnitude_acc",
"parity_acc",
"acc_diff")],
by = list(Focus = study_level$focus_group),
FUN = mean
)
acc_by_focus
str(study_level)
# What do we notice here?
# Summaries for key variables
summary(study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff",
"magnitude_acc",
"parity_acc",
"acc_diff")])
# Optional exploration: association between overall RT and overall accuracy
cor(study_level$mean_rt_overall, study_level$mean_acc_overall, use = "complete.obs")
# Make an output directory for tables if needed
dir.create(here("output/tables"), recursive = TRUE, showWarnings = FALSE)
# Build a compact one-row table of overall means and SDs
group_summary <- data.frame(
mean_magnitude_rt = mean(study_level$magnitude_mean_rt, na.rm = TRUE),
mean_parity_rt    = mean(study_level$parity_mean_rt,    na.rm = TRUE),
mean_rt_diff      = mean(study_level$rt_diff,                    na.rm = TRUE),
sd_magnitude_rt   = sd(study_level$magnitude_mean_rt,   na.rm = TRUE),
sd_parity_rt      = sd(study_level$parity_mean_rt,      na.rm = TRUE),
sd_rt_diff        = sd(study_level$rt_diff,                      na.rm = TRUE)
)
# Preview and save
group_summary
write.csv(group_summary, here("output/tables/group_summary.csv"), row.names = FALSE)
saveRDS(group_summary, here("output/tables/group_summary.rds"))
# Confirm
file.exists(here("output/tables/group_summary.csv"))
# Check for missing values
anyNA(study_level)
# Check number of participants
nrow(study_level)
source("../scripts/score_questionnaire.R")
source("../scripts/summarize_behavior.R")
source("../scripts/process_participant.R")
setwd("../")
getwd()
# Create full project folder structure under psy1903/web/
setwd("~/Desktop/psy1903") # Update to your path
dir.create("web/w11_taskset/data/raw", recursive = TRUE, showWarnings = FALSE)
dir.create("web/w11_taskset/data/cleaned", recursive = TRUE, showWarnings = FALSE)
dir.create("web/w11_taskset/scripts", recursive = TRUE, showWarnings = FALSE)
dir.create("web/w11_taskset/reports", recursive = TRUE, showWarnings = FALSE)
# Create placeholder R Script and Quarto Report files
file.create("web/w11_taskset/scripts/score_questionnaire.R")
file.create("web/w11_taskset/scripts/compute_rt_if_missing.R")
file.create("web/w11_taskset/scripts/process_participant.R")
file.create("web/w11_taskset/scripts/summarize_behavior.R”)
file.create("web/w11_taskset/reports/w11_taskset.qmd")
file.create("web/w11_taskset/scripts/summarize_behavior.R")
file.create("web/w11_taskset/reports/w11_taskset.qmd")
file.create("web/w11_taskset/w11_taskset.RProj")
project_text <- "Version: 1.0\n\nRestoreWorkspace: Default\nSaveWorkspace: Default\nAlwaysSaveHistory: Default\n\nEnableCodeIndexing: Yes\nUseSpacesForTab: Yes\nNumSpacesForTab: 4\nEncoding: UTF-8\n\nRnwWeave: Sweave\nLaTeX: pdfLaTeX"
writeLines(project_text, "web/npt_project/npt_project.RProj")
file.create(here::here("scripts/npt_dataviz.qmd"))
if (!require("pacman")) {install.packages("pacman"); require("pacman")}
p_load("ggplot2")
npt_data <- read.csv(here::here("data/cleaned/study_level_processed.csv"))
View(npt_data)
dir.create(here::here("output/plots"), recursive = TRUE, showWarnings = FALSE)
#| label: fig-example
#| fig-cap: "Example figure caption generated by Quarto."
plot(1:10, 1:10)
ggplot(data_frame, aes(x = variable_x, y = variable_y)) +
geom_layer()
#| label: fig-rt-hist
#| fig-cap: "Histogram of overall reaction times."
ggplot(npt_data, aes(x = mean_rt_overall)) +
geom_histogram(binwidth = 5,
fill = "gray80",
color = "black") +
labs(x = "Mean RT (ms)", y = "Count")
#| label: fig-rt-hist-lines
#| fig-cap: "Histogram of overall reaction times with reference lines showing the mean and one standard deviation."
## Compute summary statistics
mean_rt <- mean(npt_data$mean_rt_overall, na.rm = TRUE)
sd_rt   <- sd(npt_data$mean_rt_overall,   na.rm = TRUE)
## Histogram with reference lines
ggplot(npt_data, aes(x = mean_rt_overall)) +
geom_histogram(binwidth = 5,
fill = "gray80",
color = "black") +
geom_vline(xintercept = mean_rt,         color = "red") +
geom_vline(xintercept = mean_rt - sd_rt, color = "blue", linetype = "dashed") +
geom_vline(xintercept = mean_rt + sd_rt, color = "blue", linetype = "dashed") +
labs(x = "Mean RT (ms)", y = "Count")
#| label: fig-scatter
#| fig-cap: "Scatterplot of TEF-10 scores and overall reaction times."
ggplot(npt_data, aes(x = tef10_score, y = mean_rt_overall)) +
geom_point(color = "gray40") +
labs(x = "TEF-10 Score",
y = "Mean RT (ms)") +
theme_minimal()
#| label: fig-scatter-line
#| fig-cap: "Scatterplot with a fitted regression line showing the relationship between TEF-10 score and overall reaction time."
## Correlation test
cor_test <- cor.test(npt_data$tef10_score,
npt_data$mean_rt_overall)
## Scatterplot + regression line
ggplot(npt_data, aes(x = tef10_score, y = mean_rt_overall)) +
geom_point(color = "gray40") +
geom_smooth(method = "lm", se = FALSE, color = "blue") +
labs(x = "TEF-10 Score",
y = "Mean RT (ms)") +
theme_minimal()
#| label: fig-bar
#| fig-cap: "Mean overall reaction time by focus group."
## Compute group means
#####Before we can plot group means, we need to compute them. We will use aggregate() to create a summarized data frame with one         row per focus group.
mean_rt_by_group <- aggregate(mean_rt_overall ~ focus_group,
data = npt_data,
FUN  = mean)
mean_rt_by_group
## Extract values for dynamic reporting
mean_high <- mean_rt_by_group$mean_rt_overall[mean_rt_by_group$focus_group == "High Focus"]
mean_low  <- mean_rt_by_group$mean_rt_overall[mean_rt_by_group$focus_group == "Low Focus"]
## Plot the bar plot
ggplot(mean_rt_by_group, aes(x = focus_group, y = mean_rt_overall)) +
geom_col(fill = "steelblue") +
labs(x = "Focus Group", y = "Mean RT (ms)") +
theme_classic()
View(rt_by_focus)
## Select relevant columns
multi_rt <- npt_data[, c("focus_group",
"parity_mean_rt",
"magnitude_mean_rt")]
## Reshape to 'long' format for ggplot
multi_rt_long <- reshape(multi_rt,
varying = list(c("parity_mean_rt", "magnitude_mean_rt")),
v.names = "rt_value",
timevar = "task_type",
times = c("Parity RT", "Magnitude RT"),
direction = "long")
head(multi_rt_long)
View(multi_rt_long)
View(multi_rt_long)
## Select relevant columns
multi_rt <- npt_data[, c("focus_group",
"parity_mean_rt",
"magnitude_mean_rt")] ##selecting the three columns you want
## Reshape to 'long' format for ggplot
multi_rt_long <- reshape(multi_rt,
varying = list(c("parity_mean_rt", "magnitude_mean_rt")),
v.names = "rt_value",
timevar = "task_type",
times = c("Parity RT", "Magnitude RT"),
direction = "long")
head(multi_rt_long)
#| label: fig-multi-bar
#| fig-cap: "Comparison of parity and magnitude mean RTs across focus groups."
ggplot(multi_rt_long,
aes(x = focus_group,
y = rt_value,
fill = task_type)) +
geom_col(position = "dodge") +
labs(x = "Focus Group",
y = "Mean RT (ms)",
fill = "Task Type") +
theme_classic()
#| label: fig-multi-bar
#| fig-cap: "Comparison of parity and magnitude mean RTs across focus groups."
ggplot(multi_rt_long,
aes(x = focus_group,
y = rt_value,
fill = task_type)) +
geom_col(position = "dodge") +
labs(x = "Focus Group",
y = "Mean RT (ms)",
fill = "Task Type") +
theme_classic()
tapply(multi_rt_long$rt_value,
list(multi_rt_long$focus_group,
multi_rt_long$task_type),
mean)
## Create a plot object
p_focus <- ggplot(mean_rt_by_group,
aes(x = focus_group, y = mean_rt_overall)) +
geom_col(fill = "steelblue") +
labs(x = "Focus Group", y = "Mean RT (ms)") +
theme_minimal()
## Save the plot object
ggsave(
filename = here::here("output", "plots", "focus_group_barplot.png"),
plot     = p_focus,
width    = 6,
height   = 4
)
p_focus   # this displays the plot in the rendered document
View(study_level)
View(group_summary)
View(npt_data)
View(study_level)
